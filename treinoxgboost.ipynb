{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f9e55a",
   "metadata": {},
   "source": [
    "# XGBoost Training for Municipal Time Series Forecasting\n",
    "\n",
    "This notebook implements a comprehensive approach to training XGBoost models for each municipality (CD_MUN) in the dataset. The goal is to predict the sum of the next 4 weeks based on a 48-week lookback period.\n",
    "\n",
    "## Overview\n",
    "- **Data**: Time series data by municipality with weekly target values\n",
    "- **Approach**: One XGBoost model per municipality using sliding window\n",
    "- **Evaluation**: Comprehensive visualization and performance metrics\n",
    "\n",
    "## Table of Contents\n",
    "1. Setup and Library Imports\n",
    "2. Define Run Identifier and Load Data\n",
    "3. Data Preprocessing\n",
    "4. Feature Engineering\n",
    "5. Training Framework\n",
    "6. Model Training Loop\n",
    "7. Evaluation and Visualization\n",
    "8. Results Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb2fc8",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "First, we need to set up the environment and install necessary dependencies. **IMPORTANT: After running this cell, restart the kernel before continuing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a310d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)]\n",
      "Python executable: c:\\Users\\pedro\\OneDrive - Unesp\\Documentos\\GitHub\\treinamento_clusters_hpc\\.conda\\python.exe\n",
      "Current environment: c:\\Users\\pedro\\OneDrive - Unesp\\Documentos\\GitHub\\treinamento_clusters_hpc\\.conda\n",
      "Detected environment name: .conda\n",
      "\n",
      "Method 1: Installing ipykernel using conda...\n",
      "Conda install error: Command 'conda install -n .conda ipykernel --update-deps --force-reinstall -y' returned non-zero exit status 1.\n",
      "Output: \n",
      "Stderr: \n",
      "EnvironmentLocationNotFound: Not a conda environment: C:\\Users\\pedro\\.conda\\envs\\.conda\n",
      "\n",
      "\n",
      "\n",
      "Method 2: Installing with pip...\n",
      "Requirement already satisfied: ipykernel in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (6.29.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (1.8.11)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (9.1.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (4.12.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.7)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (308)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "Pip install completed.\n",
      "\n",
      "Installing other required packages...\n",
      "Requirement already satisfied: pandas>=1.3 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from -r requirements.txt (line 2)) (2.2.5)\n",
      "Requirement already satisfied: matplotlib>=3.4 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from -r requirements.txt (line 3)) (3.10.1)\n",
      "Requirement already satisfied: seaborn>=0.11 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from -r requirements.txt (line 4)) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from -r requirements.txt (line 5)) (1.6.1)\n",
      "Requirement already satisfied: xgboost>=1.5 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from -r requirements.txt (line 6)) (3.0.0)\n",
      "Collecting torch>=1.10 (from -r requirements.txt (line 7))\n",
      "  Downloading torch-2.7.0-cp311-cp311-win_amd64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tqdm>=4.62 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
      "Requirement already satisfied: joblib>=1.1 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from -r requirements.txt (line 9)) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from pandas>=1.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from pandas>=1.3->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from pandas>=1.3->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from matplotlib>=3.4->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from matplotlib>=3.4->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from matplotlib>=3.4->-r requirements.txt (line 3)) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from matplotlib>=3.4->-r requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from matplotlib>=3.4->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from matplotlib>=3.4->-r requirements.txt (line 3)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from matplotlib>=3.4->-r requirements.txt (line 3)) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from scikit-learn>=1.0->-r requirements.txt (line 5)) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from scikit-learn>=1.0->-r requirements.txt (line 5)) (3.6.0)\n",
      "Collecting filelock (from torch>=1.10->-r requirements.txt (line 7))\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from torch>=1.10->-r requirements.txt (line 7)) (4.12.2)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.10->-r requirements.txt (line 7))\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.10->-r requirements.txt (line 7))\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.10->-r requirements.txt (line 7))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch>=1.10->-r requirements.txt (line 7))\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from tqdm>=4.62->-r requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pedro\\onedrive - unesp\\documentos\\github\\treinamento_clusters_hpc\\.conda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3->-r requirements.txt (line 1)) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.10->-r requirements.txt (line 7))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.10->-r requirements.txt (line 7))\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading torch-2.7.0-cp311-cp311-win_amd64.whl (212.5 MB)\n",
      "   ---------------------------------------- 0.0/212.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 10.0/212.5 MB 51.9 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 21.5/212.5 MB 52.3 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 33.8/212.5 MB 53.7 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 46.7/212.5 MB 56.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 59.2/212.5 MB 57.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 73.9/212.5 MB 59.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 87.3/212.5 MB 60.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 98.0/212.5 MB 60.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 112.2/212.5 MB 60.2 MB/s eta 0:00:02\n",
      "   ---------------------- ---------------- 125.0/212.5 MB 60.0 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 137.6/212.5 MB 60.2 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 149.4/212.5 MB 60.0 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 160.4/212.5 MB 59.6 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 172.8/212.5 MB 59.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 185.1/212.5 MB 59.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 196.6/212.5 MB 59.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  208.7/212.5 MB 59.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 59.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  212.3/212.5 MB 59.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 212.5/212.5 MB 51.9 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.3/6.3 MB 55.4 MB/s eta 0:00:00\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   --------------- ------------------------ 3/8 [MarkupSafe]\n",
      "   -------------------- ------------------- 4/8 [fsspec]\n",
      "   -------------------- ------------------- 4/8 [fsspec]\n",
      "   -------------------- ------------------- 4/8 [fsspec]\n",
      "   -------------------- ------------------- 4/8 [fsspec]\n",
      "   -------------------- ------------------- 4/8 [fsspec]\n",
      "   -------------------- ------------------- 4/8 [fsspec]\n",
      "   -------------------- ------------------- 4/8 [fsspec]\n",
      "   ------------------------------ --------- 6/8 [jinja2]\n",
      "   ------------------------------ --------- 6/8 [jinja2]\n",
      "   ------------------------------ --------- 6/8 [jinja2]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ---------------------------------------- 8/8 [torch]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.7.0\n",
      "Installed packages from requirements.txt\n",
      "\n",
      "==================================================\n",
      "IMPORTANT: RESTART THE KERNEL BEFORE CONTINUING\n",
      "After restarting, the ipykernel will be properly installed.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Print current environment information\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Current environment: {sys.prefix}\")\n",
    "\n",
    "# Get the environment name\n",
    "try:\n",
    "    # Extract environment name from path\n",
    "    import os\n",
    "    env_path = sys.prefix\n",
    "    env_name = os.path.basename(env_path)\n",
    "    if env_name == '':  # If it's the base directory\n",
    "        env_name = 'base'\n",
    "    print(f\"Detected environment name: {env_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error detecting environment name: {e}\")\n",
    "    env_name = '.conda'  # Default fallback\n",
    "\n",
    "# Method 1: Install using conda system call\n",
    "print(\"\\nMethod 1: Installing ipykernel using conda...\")\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        f\"conda install -n {env_name} ipykernel --update-deps --force-reinstall -y\",\n",
    "        shell=True, check=True, capture_output=True, text=True\n",
    "    )\n",
    "    print(\"Conda install completed successfully.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Conda install error: {e}\")\n",
    "    print(\"Output:\", e.output)\n",
    "    print(\"Stderr:\", e.stderr)\n",
    "\n",
    "# Method 2: Install using pip\n",
    "print(\"\\nMethod 2: Installing with pip...\")\n",
    "try:\n",
    "    !pip install --upgrade ipykernel\n",
    "    print(\"Pip install completed.\")\n",
    "except Exception as e:\n",
    "    print(f\"Pip install error: {e}\")\n",
    "\n",
    "# Install other required packages\n",
    "print(\"\\nInstalling other required packages...\")\n",
    "!pip install pandas>=1.3 numpy>=1.21 matplotlib>=3.4 seaborn>=0.11 scikit-learn>=1.0 xgboost>=1.5 tqdm>=4.62 joblib>=1.1\n",
    "\n",
    "# Try installing from requirements.txt if it exists\n",
    "try:\n",
    "    if os.path.exists(\"requirements.txt\"):\n",
    "        !pip install -r requirements.txt\n",
    "        print(\"Installed packages from requirements.txt\")\n",
    "except Exception as e:\n",
    "    print(f\"Error installing from requirements.txt: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"IMPORTANT: RESTART THE KERNEL BEFORE CONTINUING\")\n",
    "print(\"After restarting, the ipykernel will be properly installed.\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e0cdf",
   "metadata": {},
   "source": [
    "# How to Restart the Kernel\n",
    "\n",
    "After installing packages, you need to restart the kernel for the changes to take effect. Here's how to do it:\n",
    "\n",
    "### Method 1: Using the Menu\n",
    "- Click on the `Kernel` menu at the top of the notebook\n",
    "- Select `Restart` or `Restart Kernel...`\n",
    "\n",
    "### Method 2: Using Buttons\n",
    "- Look for a restart button in the toolbar (often looks like a circular arrow ↻)\n",
    "- In VS Code, it's in the top-right corner of the notebook window\n",
    "\n",
    "### Method 3: Keyboard Shortcuts\n",
    "- In Jupyter Notebook/Lab: Press `Ctrl+M` followed by `R` (Windows/Linux) or `Cmd+M` followed by `R` (Mac)\n",
    "- In VS Code: `Ctrl+Shift+P` (Windows/Linux) or `Cmd+Shift+P` (Mac) to open the command palette, then type 'restart' and select 'Restart Kernel'\n",
    "\n",
    "After restarting, run the cells again from the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d60088",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c61bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define a simple progress bar replacement instead of using tqdm\n",
    "def simple_progress_bar(iterable=None, total=None, desc=\"Progress\"):\n",
    "    \"\"\"A very simple progress bar replacement for tqdm\"\"\"\n",
    "    if iterable is not None:\n",
    "        total = len(iterable)\n",
    "        it = iter(iterable)\n",
    "    else:\n",
    "        it = range(total)\n",
    "    \n",
    "    def progress_iterator():\n",
    "        print(f\"{desc}: 0/{total} (0%)\")\n",
    "        count = 0\n",
    "        for item in it:\n",
    "            yield item\n",
    "            count += 1\n",
    "            if count % max(1, total // 20) == 0 or count == total:  # Update ~20 times total\n",
    "                percent = int(100 * count / total)\n",
    "                print(f\"\\r{desc}: {count}/{total} ({percent}%)\", end=\"\")\n",
    "        print()  # New line at the end\n",
    "        \n",
    "    return progress_iterator() if iterable is not None else progress_iterator\n",
    "\n",
    "# Replace tqdm with our simple progress bar\n",
    "tqdm = simple_progress_bar\n",
    "trange = lambda *args, **kwargs: simple_progress_bar(range(*args), **kwargs)\n",
    "\n",
    "# Set plot styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4a2b23",
   "metadata": {},
   "source": [
    "## 2. Define Run Identifier and Load Data\n",
    "\n",
    "Before loading the data, please specify a unique identifier for this training run. This identifier will be used to create separate directories for the models, results, and visualizations, helping to organize outputs from different datasets or experiments.\n",
    "\n",
    "For example, if you are processing a dataset named 'dataset_alpha_v1', you could set `run_identifier = \"dataset_alpha_v1\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e3f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE YOUR RUN IDENTIFIER HERE\n",
    "# This name will be used to create specific subdirectories for this run's outputs.\n",
    "run_identifier = \"df_base_initial_run\"  # Example: \"series_A_experiment_1\"\n",
    "\n",
    "if not run_identifier or not isinstance(run_identifier, str) or \"\\\" in run_identifier or \"/\" in run_identifier:\n",
    "    raise ValueError(\"Please set a valid 'run_identifier' string (e.g., 'my_dataset_run_1'). It should not contain path separators.\")\n",
    "\n",
    "print(f\"Using run identifier: {run_identifier}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67d5054",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Exploration\n",
    "\n",
    "We'll load the data from either a CSV file or extract it from a ZIP archive if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from data\\df_base.csv...\n",
      "Data loaded successfully with 6684000 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "# Create timestamp for versioning\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Set up directories based on run_identifier\n",
    "base_models_dir = f'models/{run_identifier}'\n",
    "base_results_dir = f'results/{run_identifier}'\n",
    "\n",
    "models_dir = f'{base_models_dir}/xgboost_{timestamp}'\n",
    "results_dir = f'{base_results_dir}/xgboost_{timestamp}'\n",
    "data_dir = 'data' # Data directory remains the same\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in [data_dir, models_dir, results_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(f\"Run Identifier: {run_identifier}\")\n",
    "print(f\"Models will be saved in: {models_dir}\")\n",
    "print(f\"Results will be saved in: {results_dir}\")\n",
    "\n",
    "# Function to load data from CSV or extract from ZIP\n",
    "def load_data():\n",
    "    csv_path = os.path.join(data_dir, 'df_base.csv')\n",
    "    zip_path = os.path.join(data_dir, 'df_base.zip')\n",
    "    \n",
    "    if os.path.exists(csv_path):\n",
    "        print(f\"Loading data from {csv_path}...\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "    elif os.path.exists(zip_path):\n",
    "        print(f\"Extracting data from {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)\n",
    "        df = pd.read_csv(csv_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Neither {csv_path} nor {zip_path} found. Please check the data location.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    df_base = load_data()\n",
    "    print(f\"Data loaded successfully with {df_base.shape[0]} rows and {df_base.shape[1]} columns.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    # Create a dummy dataset for demonstration if needed\n",
    "    print(\"Creating dummy dataset for demonstration...\")\n",
    "    # This is just for demonstration - adjust based on your actual data structure\n",
    "    n_municipalities = 5\n",
    "    weeks_per_mun = 104  # 2 years of weekly data\n",
    "    mun_codes = [f\"{i:05d}\" for i in range(1, n_municipalities + 1)]\n",
    "    df_base = pd.DataFrame({\n",
    "        'CD_MUN': np.repeat(mun_codes, weeks_per_mun),\n",
    "        'week': np.tile(np.arange(weeks_per_mun), n_municipalities),\n",
    "        'target': np.random.normal(50, 10, n_municipalities * weeks_per_mun)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f5204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_MUN</th>\n",
       "      <th>week</th>\n",
       "      <th>target</th>\n",
       "      <th>PIB</th>\n",
       "      <th>DENS</th>\n",
       "      <th>URB</th>\n",
       "      <th>CO2</th>\n",
       "      <th>CH4</th>\n",
       "      <th>N2O</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515856</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539765</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100015</td>\n",
       "      <td>2</td>\n",
       "      <td>0.458823</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100015</td>\n",
       "      <td>3</td>\n",
       "      <td>0.485555</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100015</td>\n",
       "      <td>4</td>\n",
       "      <td>0.231805</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CD_MUN  week    target      PIB      DENS       URB         CO2  \\\n",
       "0  1100015     0  0.515856  3469.14  3.541043  0.000611  550.985905   \n",
       "1  1100015     1  0.539765  3469.14  3.541043  0.000611  550.985905   \n",
       "2  1100015     2  0.458823  3469.14  3.541043  0.000611  550.985905   \n",
       "3  1100015     3  0.485555  3469.14  3.541043  0.000611  550.985905   \n",
       "4  1100015     4  0.231805  3469.14  3.541043  0.000611  550.985905   \n",
       "\n",
       "         CH4       N2O        LAT    LON  \n",
       "0  92.946598  6.657747 -12.883213 -62.39  \n",
       "1  92.946598  6.657747 -12.883213 -62.39  \n",
       "2  92.946598  6.657747 -12.883213 -62.39  \n",
       "3  92.946598  6.657747 -12.883213 -62.39  \n",
       "4  92.946598  6.657747 -12.883213 -62.39  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CD_MUN      int64\n",
       "week        int64\n",
       "target    float64\n",
       "PIB       float64\n",
       "DENS      float64\n",
       "URB       float64\n",
       "CO2       float64\n",
       "CH4       float64\n",
       "N2O       float64\n",
       "LAT       float64\n",
       "LON       float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>target</th>\n",
       "      <th>PIB</th>\n",
       "      <th>DENS</th>\n",
       "      <th>URB</th>\n",
       "      <th>CO2</th>\n",
       "      <th>CH4</th>\n",
       "      <th>N2O</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.684000e+06</td>\n",
       "      <td>6.684000e+06</td>\n",
       "      <td>6.003816e+06</td>\n",
       "      <td>6.033600e+06</td>\n",
       "      <td>6.033600e+06</td>\n",
       "      <td>6.033600e+06</td>\n",
       "      <td>6.033600e+06</td>\n",
       "      <td>6.033600e+06</td>\n",
       "      <td>6.033600e+06</td>\n",
       "      <td>6.033600e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.995000e+02</td>\n",
       "      <td>4.710729e-01</td>\n",
       "      <td>1.397299e+04</td>\n",
       "      <td>8.091379e+01</td>\n",
       "      <td>1.268524e-02</td>\n",
       "      <td>3.953797e+04</td>\n",
       "      <td>7.463403e+02</td>\n",
       "      <td>1.116126e+01</td>\n",
       "      <td>-1.638302e+01</td>\n",
       "      <td>-4.637996e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.464101e+02</td>\n",
       "      <td>3.616928e+00</td>\n",
       "      <td>1.973538e+04</td>\n",
       "      <td>3.952444e+02</td>\n",
       "      <td>4.668693e-02</td>\n",
       "      <td>1.244388e+05</td>\n",
       "      <td>1.332048e+04</td>\n",
       "      <td>2.845796e+01</td>\n",
       "      <td>8.354524e+00</td>\n",
       "      <td>6.424812e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.459830e+03</td>\n",
       "      <td>3.143629e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.365254e+01</td>\n",
       "      <td>-7.348400e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.997500e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.516650e+03</td>\n",
       "      <td>1.112562e+01</td>\n",
       "      <td>1.319166e-03</td>\n",
       "      <td>4.454221e+03</td>\n",
       "      <td>6.922971e+01</td>\n",
       "      <td>4.712564e+00</td>\n",
       "      <td>-2.279264e+01</td>\n",
       "      <td>-5.102275e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.995000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.607535e+03</td>\n",
       "      <td>2.363456e+01</td>\n",
       "      <td>2.999792e-03</td>\n",
       "      <td>1.128696e+04</td>\n",
       "      <td>1.379897e+02</td>\n",
       "      <td>8.660524e+00</td>\n",
       "      <td>-1.785337e+01</td>\n",
       "      <td>-4.661550e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.992500e+02</td>\n",
       "      <td>2.773210e-01</td>\n",
       "      <td>1.684539e+04</td>\n",
       "      <td>4.817254e+01</td>\n",
       "      <td>7.148583e-03</td>\n",
       "      <td>2.817704e+04</td>\n",
       "      <td>2.405503e+02</td>\n",
       "      <td>1.352129e+01</td>\n",
       "      <td>-8.456431e+00</td>\n",
       "      <td>-4.166000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.199000e+03</td>\n",
       "      <td>7.359496e+02</td>\n",
       "      <td>9.208340e+05</td>\n",
       "      <td>1.344249e+04</td>\n",
       "      <td>9.768962e-01</td>\n",
       "      <td>3.137265e+06</td>\n",
       "      <td>7.075641e+05</td>\n",
       "      <td>3.683565e+03</td>\n",
       "      <td>4.685425e+00</td>\n",
       "      <td>-3.487000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               week        target           PIB          DENS           URB  \\\n",
       "count  6.684000e+06  6.684000e+06  6.003816e+06  6.033600e+06  6.033600e+06   \n",
       "mean   5.995000e+02  4.710729e-01  1.397299e+04  8.091379e+01  1.268524e-02   \n",
       "std    3.464101e+02  3.616928e+00  1.973538e+04  3.952444e+02  4.668693e-02   \n",
       "min    0.000000e+00  0.000000e+00 -1.459830e+03  3.143629e-02  0.000000e+00   \n",
       "25%    2.997500e+02  0.000000e+00  4.516650e+03  1.112562e+01  1.319166e-03   \n",
       "50%    5.995000e+02  0.000000e+00  8.607535e+03  2.363456e+01  2.999792e-03   \n",
       "75%    8.992500e+02  2.773210e-01  1.684539e+04  4.817254e+01  7.148583e-03   \n",
       "max    1.199000e+03  7.359496e+02  9.208340e+05  1.344249e+04  9.768962e-01   \n",
       "\n",
       "                CO2           CH4           N2O           LAT           LON  \n",
       "count  6.033600e+06  6.033600e+06  6.033600e+06  6.033600e+06  6.033600e+06  \n",
       "mean   3.953797e+04  7.463403e+02  1.116126e+01 -1.638302e+01 -4.637996e+01  \n",
       "std    1.244388e+05  1.332048e+04  2.845796e+01  8.354524e+00  6.424812e+00  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00 -3.365254e+01 -7.348400e+01  \n",
       "25%    4.454221e+03  6.922971e+01  4.712564e+00 -2.279264e+01 -5.102275e+01  \n",
       "50%    1.128696e+04  1.379897e+02  8.660524e+00 -1.785337e+01 -4.661550e+01  \n",
       "75%    2.817704e+04  2.405503e+02  1.352129e+01 -8.456431e+00 -4.166000e+01  \n",
       "max    3.137265e+06  7.075641e+05  3.683565e+03  4.685425e+00 -3.487000e+01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CD_MUN         0\n",
       "week           0\n",
       "target         0\n",
       "PIB       680184\n",
       "DENS      650400\n",
       "URB       650400\n",
       "CO2       650400\n",
       "CH4       650400\n",
       "N2O       650400\n",
       "LAT       650400\n",
       "LON       650400\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique municipalities: 5570\n",
      "\n",
      "Data distribution by municipality:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    5570.0\n",
       "mean     1200.0\n",
       "std         0.0\n",
       "min      1200.0\n",
       "25%      1200.0\n",
       "50%      1200.0\n",
       "75%      1200.0\n",
       "max      1200.0\n",
       "Name: count, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic data exploration\n",
    "print(\"Data overview:\")\n",
    "display(df_base.head())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "display(df_base.dtypes)\n",
    "\n",
    "# Convert CD_MUN to string if not already\n",
    "df_base[\"CD_MUN\"] = df_base[\"CD_MUN\"].astype(str)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(df_base.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "display(df_base.isnull().sum())\n",
    "\n",
    "# Count municipalities\n",
    "n_municipalities = df_base[\"CD_MUN\"].nunique()\n",
    "print(f\"\\nNumber of unique municipalities: {n_municipalities}\")\n",
    "\n",
    "# Check data distribution by municipality\n",
    "mun_counts = df_base[\"CD_MUN\"].value_counts()\n",
    "print(f\"\\nData distribution by municipality:\")\n",
    "display(mun_counts.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86436f2e",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Here we'll prepare the data for time series modeling. This includes normalization and handling date/time information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3859d1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing target values per municipality...\n",
      "Creating date features from week column...\n",
      "Data preprocessing completed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_MUN</th>\n",
       "      <th>week</th>\n",
       "      <th>target</th>\n",
       "      <th>PIB</th>\n",
       "      <th>DENS</th>\n",
       "      <th>URB</th>\n",
       "      <th>CO2</th>\n",
       "      <th>CH4</th>\n",
       "      <th>N2O</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>target_norm</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>week_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515856</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539765</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100015</td>\n",
       "      <td>2</td>\n",
       "      <td>0.458823</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100015</td>\n",
       "      <td>3</td>\n",
       "      <td>0.485555</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "      <td>0.871500</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100015</td>\n",
       "      <td>4</td>\n",
       "      <td>0.231805</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "      <td>-0.084223</td>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CD_MUN  week    target      PIB      DENS       URB         CO2  \\\n",
       "0  1100015     0  0.515856  3469.14  3.541043  0.000611  550.985905   \n",
       "1  1100015     1  0.539765  3469.14  3.541043  0.000611  550.985905   \n",
       "2  1100015     2  0.458823  3469.14  3.541043  0.000611  550.985905   \n",
       "3  1100015     3  0.485555  3469.14  3.541043  0.000611  550.985905   \n",
       "4  1100015     4  0.231805  3469.14  3.541043  0.000611  550.985905   \n",
       "\n",
       "         CH4       N2O        LAT    LON  target_norm       date  year  month  \\\n",
       "0  92.946598  6.657747 -12.883213 -62.39     0.985625 2018-01-01  2018      1   \n",
       "1  92.946598  6.657747 -12.883213 -62.39     1.075675 2018-01-08  2018      1   \n",
       "2  92.946598  6.657747 -12.883213 -62.39     0.770817 2018-01-15  2018      1   \n",
       "3  92.946598  6.657747 -12.883213 -62.39     0.871500 2018-01-22  2018      1   \n",
       "4  92.946598  6.657747 -12.883213 -62.39    -0.084223 2018-01-29  2018      1   \n",
       "\n",
       "   day_of_week  day_of_year  week_of_year  \n",
       "0            0            1             1  \n",
       "1            0            8             2  \n",
       "2            0           15             3  \n",
       "3            0           22             4  \n",
       "4            0           29             5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize target values per municipality\n",
    "print(\"Normalizing target values per municipality...\")\n",
    "df_base[\"target_norm\"] = df_base.groupby(\"CD_MUN\")[\"target\"].transform(\n",
    "    lambda x: (x - x.mean()) / (x.std() + 1e-8)\n",
    ")\n",
    "\n",
    "# Ensure data is ordered by municipality and week\n",
    "df_base = df_base.sort_values([\"CD_MUN\", \"week\"])\n",
    "\n",
    "# Check if we have any date columns; if not, create a date feature\n",
    "if not any(col.lower() in ['date', 'datetime', 'time'] for col in df_base.columns):\n",
    "    print(\"Creating date features from week column...\")\n",
    "    # Assuming week is a sequential counter (0, 1, 2, ...) for each municipality\n",
    "    df_base['date'] = pd.to_datetime('2018-01-01') + \\\n",
    "                     pd.to_timedelta(df_base['week'] * 7, unit='D')\n",
    "    \n",
    "    # Extract date components\n",
    "    df_base['year'] = df_base['date'].dt.year\n",
    "    df_base['month'] = df_base['date'].dt.month\n",
    "    df_base['day_of_week'] = df_base['date'].dt.dayofweek\n",
    "    df_base['day_of_year'] = df_base['date'].dt.dayofyear\n",
    "    df_base['week_of_year'] = df_base['date'].dt.isocalendar().week\n",
    "    \n",
    "print(\"Data preprocessing completed.\")\n",
    "display(df_base.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125422c9",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Here we'll create features specific to time series modeling, focusing on implementing a sliding window approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd769a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lag features...\n",
      "Creating rolling window features...\n",
      "Creating target features...\n",
      "Feature engineering completed.\n",
      "Total features created: 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD_MUN</th>\n",
       "      <th>week</th>\n",
       "      <th>target</th>\n",
       "      <th>PIB</th>\n",
       "      <th>DENS</th>\n",
       "      <th>URB</th>\n",
       "      <th>CO2</th>\n",
       "      <th>CH4</th>\n",
       "      <th>N2O</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>target_norm</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>target_norm_lag_1</th>\n",
       "      <th>target_norm_lag_2</th>\n",
       "      <th>target_norm_lag_3</th>\n",
       "      <th>target_norm_lag_4</th>\n",
       "      <th>target_norm_lag_8</th>\n",
       "      <th>target_norm_lag_12</th>\n",
       "      <th>target_norm_lag_24</th>\n",
       "      <th>target_norm_lag_48</th>\n",
       "      <th>target_norm_rolling_mean_4</th>\n",
       "      <th>target_norm_rolling_std_4</th>\n",
       "      <th>target_norm_rolling_min_4</th>\n",
       "      <th>target_norm_rolling_max_4</th>\n",
       "      <th>target_norm_rolling_mean_8</th>\n",
       "      <th>target_norm_rolling_std_8</th>\n",
       "      <th>target_norm_rolling_min_8</th>\n",
       "      <th>target_norm_rolling_max_8</th>\n",
       "      <th>target_norm_rolling_mean_12</th>\n",
       "      <th>target_norm_rolling_std_12</th>\n",
       "      <th>target_norm_rolling_min_12</th>\n",
       "      <th>target_norm_rolling_max_12</th>\n",
       "      <th>target_norm_rolling_mean_24</th>\n",
       "      <th>target_norm_rolling_std_24</th>\n",
       "      <th>target_norm_rolling_min_24</th>\n",
       "      <th>target_norm_rolling_max_24</th>\n",
       "      <th>target_norm_rolling_mean_48</th>\n",
       "      <th>target_norm_rolling_std_48</th>\n",
       "      <th>target_norm_rolling_min_48</th>\n",
       "      <th>target_norm_rolling_max_48</th>\n",
       "      <th>target_next_4_sum</th>\n",
       "      <th>target_next_4_sum_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1100015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.515856</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>1.715949</td>\n",
       "      <td>0.774298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1100015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539765</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.030650</td>\n",
       "      <td>0.063675</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>1.030650</td>\n",
       "      <td>0.063675</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>1.030650</td>\n",
       "      <td>0.063675</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>1.030650</td>\n",
       "      <td>0.063675</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>1.030650</td>\n",
       "      <td>0.063675</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>1.409381</td>\n",
       "      <td>0.438793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1100015</td>\n",
       "      <td>2</td>\n",
       "      <td>0.458823</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.944039</td>\n",
       "      <td>0.156626</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.944039</td>\n",
       "      <td>0.156626</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.944039</td>\n",
       "      <td>0.156626</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.944039</td>\n",
       "      <td>0.156626</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.944039</td>\n",
       "      <td>0.156626</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>1.226187</td>\n",
       "      <td>0.238308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100015</td>\n",
       "      <td>3</td>\n",
       "      <td>0.485555</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "      <td>0.871500</td>\n",
       "      <td>2018-01-22</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.925904</td>\n",
       "      <td>0.132928</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.925904</td>\n",
       "      <td>0.132928</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.925904</td>\n",
       "      <td>0.132928</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.925904</td>\n",
       "      <td>0.132928</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.925904</td>\n",
       "      <td>0.132928</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100015</td>\n",
       "      <td>4</td>\n",
       "      <td>0.231805</td>\n",
       "      <td>3469.14</td>\n",
       "      <td>3.541043</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>550.985905</td>\n",
       "      <td>92.946598</td>\n",
       "      <td>6.657747</td>\n",
       "      <td>-12.883213</td>\n",
       "      <td>-62.39</td>\n",
       "      <td>-0.084223</td>\n",
       "      <td>2018-01-29</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0.871500</td>\n",
       "      <td>0.770817</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.985625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658442</td>\n",
       "      <td>0.511096</td>\n",
       "      <td>-0.084223</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.723879</td>\n",
       "      <td>0.466180</td>\n",
       "      <td>-0.084223</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.723879</td>\n",
       "      <td>0.466180</td>\n",
       "      <td>-0.084223</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.723879</td>\n",
       "      <td>0.466180</td>\n",
       "      <td>-0.084223</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>0.723879</td>\n",
       "      <td>0.466180</td>\n",
       "      <td>-0.084223</td>\n",
       "      <td>1.075675</td>\n",
       "      <td>1.286916</td>\n",
       "      <td>0.304770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CD_MUN  week    target      PIB      DENS       URB         CO2  \\\n",
       "0  1100015     0  0.515856  3469.14  3.541043  0.000611  550.985905   \n",
       "1  1100015     1  0.539765  3469.14  3.541043  0.000611  550.985905   \n",
       "2  1100015     2  0.458823  3469.14  3.541043  0.000611  550.985905   \n",
       "3  1100015     3  0.485555  3469.14  3.541043  0.000611  550.985905   \n",
       "4  1100015     4  0.231805  3469.14  3.541043  0.000611  550.985905   \n",
       "\n",
       "         CH4       N2O        LAT    LON  target_norm       date  year  month  \\\n",
       "0  92.946598  6.657747 -12.883213 -62.39     0.985625 2018-01-01  2018      1   \n",
       "1  92.946598  6.657747 -12.883213 -62.39     1.075675 2018-01-08  2018      1   \n",
       "2  92.946598  6.657747 -12.883213 -62.39     0.770817 2018-01-15  2018      1   \n",
       "3  92.946598  6.657747 -12.883213 -62.39     0.871500 2018-01-22  2018      1   \n",
       "4  92.946598  6.657747 -12.883213 -62.39    -0.084223 2018-01-29  2018      1   \n",
       "\n",
       "   day_of_week  day_of_year  week_of_year  target_norm_lag_1  \\\n",
       "0            0            1             1                NaN   \n",
       "1            0            8             2           0.985625   \n",
       "2            0           15             3           1.075675   \n",
       "3            0           22             4           0.770817   \n",
       "4            0           29             5           0.871500   \n",
       "\n",
       "   target_norm_lag_2  target_norm_lag_3  target_norm_lag_4  target_norm_lag_8  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2           0.985625                NaN                NaN                NaN   \n",
       "3           1.075675           0.985625                NaN                NaN   \n",
       "4           0.770817           1.075675           0.985625                NaN   \n",
       "\n",
       "   target_norm_lag_12  target_norm_lag_24  target_norm_lag_48  \\\n",
       "0                 NaN                 NaN                 NaN   \n",
       "1                 NaN                 NaN                 NaN   \n",
       "2                 NaN                 NaN                 NaN   \n",
       "3                 NaN                 NaN                 NaN   \n",
       "4                 NaN                 NaN                 NaN   \n",
       "\n",
       "   target_norm_rolling_mean_4  target_norm_rolling_std_4  \\\n",
       "0                    0.985625                        NaN   \n",
       "1                    1.030650                   0.063675   \n",
       "2                    0.944039                   0.156626   \n",
       "3                    0.925904                   0.132928   \n",
       "4                    0.658442                   0.511096   \n",
       "\n",
       "   target_norm_rolling_min_4  target_norm_rolling_max_4  \\\n",
       "0                   0.985625                   0.985625   \n",
       "1                   0.985625                   1.075675   \n",
       "2                   0.770817                   1.075675   \n",
       "3                   0.770817                   1.075675   \n",
       "4                  -0.084223                   1.075675   \n",
       "\n",
       "   target_norm_rolling_mean_8  target_norm_rolling_std_8  \\\n",
       "0                    0.985625                        NaN   \n",
       "1                    1.030650                   0.063675   \n",
       "2                    0.944039                   0.156626   \n",
       "3                    0.925904                   0.132928   \n",
       "4                    0.723879                   0.466180   \n",
       "\n",
       "   target_norm_rolling_min_8  target_norm_rolling_max_8  \\\n",
       "0                   0.985625                   0.985625   \n",
       "1                   0.985625                   1.075675   \n",
       "2                   0.770817                   1.075675   \n",
       "3                   0.770817                   1.075675   \n",
       "4                  -0.084223                   1.075675   \n",
       "\n",
       "   target_norm_rolling_mean_12  target_norm_rolling_std_12  \\\n",
       "0                     0.985625                         NaN   \n",
       "1                     1.030650                    0.063675   \n",
       "2                     0.944039                    0.156626   \n",
       "3                     0.925904                    0.132928   \n",
       "4                     0.723879                    0.466180   \n",
       "\n",
       "   target_norm_rolling_min_12  target_norm_rolling_max_12  \\\n",
       "0                    0.985625                    0.985625   \n",
       "1                    0.985625                    1.075675   \n",
       "2                    0.770817                    1.075675   \n",
       "3                    0.770817                    1.075675   \n",
       "4                   -0.084223                    1.075675   \n",
       "\n",
       "   target_norm_rolling_mean_24  target_norm_rolling_std_24  \\\n",
       "0                     0.985625                         NaN   \n",
       "1                     1.030650                    0.063675   \n",
       "2                     0.944039                    0.156626   \n",
       "3                     0.925904                    0.132928   \n",
       "4                     0.723879                    0.466180   \n",
       "\n",
       "   target_norm_rolling_min_24  target_norm_rolling_max_24  \\\n",
       "0                    0.985625                    0.985625   \n",
       "1                    0.985625                    1.075675   \n",
       "2                    0.770817                    1.075675   \n",
       "3                    0.770817                    1.075675   \n",
       "4                   -0.084223                    1.075675   \n",
       "\n",
       "   target_norm_rolling_mean_48  target_norm_rolling_std_48  \\\n",
       "0                     0.985625                         NaN   \n",
       "1                     1.030650                    0.063675   \n",
       "2                     0.944039                    0.156626   \n",
       "3                     0.925904                    0.132928   \n",
       "4                     0.723879                    0.466180   \n",
       "\n",
       "   target_norm_rolling_min_48  target_norm_rolling_max_48  target_next_4_sum  \\\n",
       "0                    0.985625                    0.985625           1.715949   \n",
       "1                    0.985625                    1.075675           1.409381   \n",
       "2                    0.770817                    1.075675           1.226187   \n",
       "3                    0.770817                    1.075675           1.000000   \n",
       "4                   -0.084223                    1.075675           1.286916   \n",
       "\n",
       "   target_next_4_sum_norm  \n",
       "0                0.774298  \n",
       "1                0.438793  \n",
       "2                0.238308  \n",
       "3               -0.009228  \n",
       "4                0.304770  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define feature engineering functions\n",
    "def create_lag_features(df, target_col, lag_list, group_col=\"CD_MUN\"):\n",
    "    \"\"\"Create lag features for a grouped time series.\"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    for lag in lag_list:\n",
    "        lag_col = f\"{target_col}_lag_{lag}\"\n",
    "        df_copy[lag_col] = df_copy.groupby(group_col)[target_col].shift(lag)\n",
    "        \n",
    "    return df_copy\n",
    "\n",
    "def create_rolling_features(df, target_col, windows, group_col=\"CD_MUN\"):\n",
    "    \"\"\"Create rolling window features (mean, std, min, max) for a grouped time series.\"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    for window in windows:\n",
    "        # Rolling mean\n",
    "        df_copy[f\"{target_col}_rolling_mean_{window}\"] = (\n",
    "            df_copy.groupby(group_col)[target_col]\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .mean()\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "        \n",
    "        # Rolling std\n",
    "        df_copy[f\"{target_col}_rolling_std_{window}\"] = (\n",
    "            df_copy.groupby(group_col)[target_col]\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .std()\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "        \n",
    "        # Rolling min/max\n",
    "        df_copy[f\"{target_col}_rolling_min_{window}\"] = (\n",
    "            df_copy.groupby(group_col)[target_col]\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .min()\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "        \n",
    "        df_copy[f\"{target_col}_rolling_max_{window}\"] = (\n",
    "            df_copy.groupby(group_col)[target_col]\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .max()\n",
    "            .reset_index(level=0, drop=True)\n",
    "        )\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def create_target_features(df, target_col, forecast_periods=4, group_col=\"CD_MUN\"):\n",
    "    \"\"\"Create target features (sum of next n periods) for a grouped time series.\"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Create the target: sum of next 4 weeks\n",
    "    target_values = []\n",
    "    \n",
    "    for _, group in df_copy.groupby(group_col):\n",
    "        group_values = group[target_col].values\n",
    "        target_array = np.zeros(len(group_values))\n",
    "        \n",
    "        for i in range(len(group_values) - forecast_periods):\n",
    "            target_array[i] = np.sum(group_values[i+1:i+1+forecast_periods])\n",
    "            \n",
    "        target_values.append(target_array)\n",
    "    \n",
    "    df_copy[f\"{target_col}_next_{forecast_periods}_sum\"] = np.concatenate(target_values)\n",
    "    \n",
    "    # Create the normalized target (using group stats)\n",
    "    df_copy[f\"{target_col}_next_{forecast_periods}_sum_norm\"] = (\n",
    "        df_copy.groupby(group_col)[f\"{target_col}_next_{forecast_periods}_sum\"]\n",
    "        .transform(lambda x: (x - x.mean()) / (x.std() + 1e-8))\n",
    "    )\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"Creating lag features...\")\n",
    "lags = [1, 2, 3, 4, 8, 12, 24, 48]  # Weekly lags\n",
    "df_features = create_lag_features(df_base, \"target_norm\", lags)\n",
    "\n",
    "print(\"Creating rolling window features...\")\n",
    "windows = [4, 8, 12, 24, 48]  # Weekly rolling windows\n",
    "df_features = create_rolling_features(df_features, \"target_norm\", windows)\n",
    "\n",
    "print(\"Creating target features...\")\n",
    "df_features = create_target_features(df_features, \"target\", forecast_periods=4)\n",
    "\n",
    "print(\"Feature engineering completed.\")\n",
    "print(f\"Total features created: {df_features.shape[1] - df_base.shape[1]}\")\n",
    "\n",
    "# Display the resulting dataframe\n",
    "display(df_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe29cc",
   "metadata": {},
   "source": [
    "## 5. Training Framework\n",
    "\n",
    "Here we'll set up the framework for training the XGBoost models, including time series splitting and model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "531b5fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed. Train shape: (5704872, 48), Test shape: (60336, 48)\n",
      "Number of features: 42\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "LOOKBACK_PERIOD = 48  # 48 weeks lookback\n",
    "FORECAST_HORIZON = 4  # Predict sum of next 4 weeks\n",
    "TEST_SIZE = 12  # Use last 12 weeks for testing\n",
    "\n",
    "# Define time series split function\n",
    "def time_series_split(df, test_size=TEST_SIZE, min_train_size=LOOKBACK_PERIOD+FORECAST_HORIZON, group_col=\"CD_MUN\"):\n",
    "    \"\"\"Split a dataframe into training and testing sets by municipality, preserving time order.\"\"\"\n",
    "    train_dfs = []\n",
    "    test_dfs = []\n",
    "    skipped_munis = []\n",
    "    \n",
    "    for mun, group in df.groupby(group_col):\n",
    "        if len(group) < min_train_size + test_size:\n",
    "            skipped_munis.append(mun)\n",
    "            continue\n",
    "            \n",
    "        # Split by index (preserving time order)\n",
    "        split_idx = len(group) - test_size\n",
    "        train_dfs.append(group.iloc[:split_idx])\n",
    "        test_dfs.append(group.iloc[split_idx:])\n",
    "    \n",
    "    if skipped_munis:\n",
    "        print(f\"Skipped {len(skipped_munis)} municipalities with insufficient data\")\n",
    "    \n",
    "    if not train_dfs or not test_dfs:\n",
    "        raise ValueError(\"No valid municipalities found with sufficient data.\")\n",
    "        \n",
    "    return pd.concat(train_dfs), pd.concat(test_dfs), skipped_munis\n",
    "\n",
    "# Function to prepare X, y for a single municipality\n",
    "def prepare_xy_data(df, target_col, feature_cols):\n",
    "    \"\"\"Prepare X and y data, removing rows with NaN from feature engineering.\"\"\"\n",
    "    df_valid = df.dropna(subset=feature_cols + [target_col])\n",
    "    X = df_valid[feature_cols].values\n",
    "    y = df_valid[target_col].values\n",
    "    return X, y, df_valid\n",
    "\n",
    "# Split data into train and test sets\n",
    "try:\n",
    "    # Drop NaN values from feature engineering\n",
    "    df_features_clean = df_features.dropna()\n",
    "    \n",
    "    # Define feature columns (excluding target columns and metadata)\n",
    "    exclude_cols = [\n",
    "        'target_next_4_sum', 'target_next_4_sum_norm', \n",
    "        'CD_MUN', 'week', 'target', 'date'\n",
    "    ]\n",
    "    feature_cols = [col for col in df_features_clean.columns \n",
    "                   if col not in exclude_cols]\n",
    "    \n",
    "    # Perform the split\n",
    "    df_train, df_test, skipped_munis = time_series_split(df_features_clean)\n",
    "    print(f\"Data split completed. Train shape: {df_train.shape}, Test shape: {df_test.shape}\")\n",
    "    print(f\"Number of features: {len(feature_cols)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in data splitting: {e}\")\n",
    "    # Create placeholder dataframes in case of error\n",
    "    df_train = df_features_clean.iloc[:int(0.8*len(df_features_clean))]\n",
    "    df_test = df_features_clean.iloc[int(0.8*len(df_features_clean)):]\n",
    "    feature_cols = [col for col in df_features_clean.columns \n",
    "                   if col not in ['target_next_4_sum', 'target_next_4_sum_norm', \n",
    "                                 'CD_MUN', 'week', 'target']]\n",
    "    skipped_munis = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed7837b",
   "metadata": {},
   "source": [
    "## 6. Model Training Loop\n",
    "\n",
    "Now we'll train one XGBoost model per municipality using the prepared features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb9a5cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models for 5028 municipalities...\n",
      "0/5028 (0%)\n",
      "5028/5028 (100%)\n",
      "Training completed. 5028 models trained successfully.\n",
      "Errors occurred for 0 municipalities.\n",
      "Training results saved to results/xgboost_20250505_115446\\training_results.pkl\n"
     ]
    }
   ],
   "source": [
    "# Configure XGBoost parameters\n",
    "xgb_params = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0,\n",
    "    'reg_alpha': 0,\n",
    "    'reg_lambda': 1,\n",
    "    'random_state': RANDOM_SEED,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Function to train a model for a single municipality\n",
    "def train_municipality_model(mun_code, train_df, test_df, feature_cols,\n",
    "                            target_col='target_next_4_sum_norm',\n",
    "                            params=xgb_params):\n",
    "    \"\"\"Train and evaluate XGBoost model for a single municipality.\"\"\"\n",
    "    # Filter data for this municipality\n",
    "    mun_train = train_df[train_df['CD_MUN'] == mun_code]\n",
    "    mun_test = test_df[test_df['CD_MUN'] == mun_code]\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X_train, y_train, valid_train = prepare_xy_data(mun_train, target_col, feature_cols)\n",
    "    X_test, y_test, valid_test = prepare_xy_data(mun_test, target_col, feature_cols)\n",
    "    \n",
    "    # Skip if insufficient data\n",
    "    if len(X_train) < 10 or len(X_test) < 2:\n",
    "        return None, None, None, None, f\"Insufficient data for municipality {mun_code}\"\n",
    "    \n",
    "    # Train XGBoost model\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Save results for evaluation\n",
    "    train_results = valid_train.copy()\n",
    "    train_results['prediction_norm'] = y_pred_train\n",
    "    \n",
    "    test_results = valid_test.copy()\n",
    "    test_results['prediction_norm'] = y_pred_test\n",
    "    \n",
    "    # Denormalize predictions\n",
    "    # Get statistics from the original dataframe for denormalization\n",
    "    mun_stats = df_features[df_features['CD_MUN'] == mun_code]['target_next_4_sum']\n",
    "    target_mean = mun_stats.mean()\n",
    "    target_std = mun_stats.std()\n",
    "    \n",
    "    # Denormalize predictions\n",
    "    train_results['prediction'] = y_pred_train * target_std + target_mean\n",
    "    test_results['prediction'] = y_pred_test * target_std + target_mean\n",
    "    \n",
    "    return model, train_results, test_results, feature_cols, None\n",
    "\n",
    "# Function to train models for all municipalities\n",
    "def train_all_municipalities(train_df, test_df, feature_cols, model_dir):\n",
    "    \"\"\"Train XGBoost models for all municipalities in the dataset.\"\"\"\n",
    "    all_municipalities = sorted(train_df['CD_MUN'].unique())\n",
    "    \n",
    "    results = {\n",
    "        'models': {},\n",
    "        'train_results': {},\n",
    "        'test_results': {},\n",
    "        'feature_cols': feature_cols,\n",
    "        'errors': {}\n",
    "    }\n",
    "    \n",
    "    print(f\"Training models for {len(all_municipalities)} municipalities...\")\n",
    "    \n",
    "    # Use manual counter instead of tqdm\n",
    "    total_munis = len(all_municipalities)\n",
    "    print(f\"0/{total_munis} (0%)\")\n",
    "    \n",
    "    for i, mun_code in enumerate(all_municipalities):\n",
    "        try:\n",
    "            model, train_res, test_res, feat_cols, error = train_municipality_model(\n",
    "                mun_code, train_df, test_df, feature_cols)\n",
    "            \n",
    "            if error:\n",
    "                results['errors'][mun_code] = error\n",
    "                continue\n",
    "                \n",
    "            # Save results\n",
    "            results['models'][mun_code] = model\n",
    "            results['train_results'][mun_code] = train_res\n",
    "            results['test_results'][mun_code] = test_res\n",
    "            \n",
    "            # Save model to disk\n",
    "            mun_dir = os.path.join(model_dir, mun_code)\n",
    "            os.makedirs(mun_dir, exist_ok=True)\n",
    "            joblib.dump(model, os.path.join(mun_dir, 'model.pkl'))\n",
    "            \n",
    "            # Print progress every 50 items or at the end\n",
    "            if (i + 1) % 50 == 0 or i + 1 == total_munis:\n",
    "                percent = int(100 * (i + 1) / total_munis)\n",
    "                print(f\"\\r{i + 1}/{total_munis} ({percent}%)\", end=\"\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            results['errors'][mun_code] = str(e)\n",
    "            print(f\"\\nError training model for municipality {mun_code}: {e}\")\n",
    "    \n",
    "    print()  # Add a new line after the progress display\n",
    "    print(f\"Training completed. {len(results['models'])} models trained successfully.\")\n",
    "    print(f\"Errors occurred for {len(results['errors'])} municipalities.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Train all models\n",
    "try:\n",
    "    training_results = train_all_municipalities(df_train, df_test, feature_cols, models_dir)\n",
    "    \n",
    "    # Save training results\n",
    "    results_file = os.path.join(results_dir, 'training_results.pkl')\n",
    "    joblib.dump(training_results, results_file)\n",
    "    print(f\"Training results saved to {results_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in model training: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5acd50",
   "metadata": {},
   "source": [
    "## 7. Evaluation and Visualization\n",
    "\n",
    "Now we'll evaluate the models and create comprehensive visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e526ad71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics saved to results/xgboost_20250505_115446\\evaluation_metrics.pkl\n",
      "\n",
      "Aggregate Test Metrics (Normalized):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5028.000000</td>\n",
       "      <td>5028.000000</td>\n",
       "      <td>5.028000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.912692</td>\n",
       "      <td>1.088112</td>\n",
       "      <td>-2.062272e+31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.476112</td>\n",
       "      <td>0.547626</td>\n",
       "      <td>1.439847e+32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.012371</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>-3.586719e+33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.590019</td>\n",
       "      <td>0.716323</td>\n",
       "      <td>-2.073606e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.826360</td>\n",
       "      <td>0.991476</td>\n",
       "      <td>-5.304416e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.131942</td>\n",
       "      <td>1.348222</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.651602</td>\n",
       "      <td>4.843684</td>\n",
       "      <td>9.847828e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE         RMSE            R2\n",
       "count  5028.000000  5028.000000  5.028000e+03\n",
       "mean      0.912692     1.088112 -2.062272e+31\n",
       "std       0.476112     0.547626  1.439847e+32\n",
       "min       0.012371     0.014906 -3.586719e+33\n",
       "25%       0.590019     0.716323 -2.073606e+00\n",
       "50%       0.826360     0.991476 -5.304416e-01\n",
       "75%       1.131942     1.348222  0.000000e+00\n",
       "max       4.651602     4.843684  9.847828e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregate Test Metrics (Denormalized):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5028.000000</td>\n",
       "      <td>5028.000000</td>\n",
       "      <td>5028.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.785864</td>\n",
       "      <td>0.938022</td>\n",
       "      <td>-7.889956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.298722</td>\n",
       "      <td>1.487579</td>\n",
       "      <td>138.031595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>-7200.657771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.348114</td>\n",
       "      <td>0.412969</td>\n",
       "      <td>-1.358671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.545706</td>\n",
       "      <td>0.657979</td>\n",
       "      <td>-0.318405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.888948</td>\n",
       "      <td>1.063561</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.616640</td>\n",
       "      <td>70.368439</td>\n",
       "      <td>0.984783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MAE         RMSE           R2\n",
       "count  5028.000000  5028.000000  5028.000000\n",
       "mean      0.785864     0.938022    -7.889956\n",
       "std       1.298722     1.487579   138.031595\n",
       "min       0.002904     0.002934 -7200.657771\n",
       "25%       0.348114     0.412969    -1.358671\n",
       "50%       0.545706     0.657979    -0.318405\n",
       "75%       0.888948     1.063561     0.000000\n",
       "max      63.616640    70.368439     0.984783"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to calculate evaluation metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate regression metrics.\"\"\"\n",
    "    metrics = {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'R2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Function to create evaluation report\n",
    "def create_evaluation_report(training_results):\n",
    "    \"\"\"Create evaluation report for all municipalities.\"\"\"\n",
    "    metrics = {\n",
    "        'normalized': {'train': {}, 'test': {}},\n",
    "        'denormalized': {'train': {}, 'test': {}}\n",
    "    }\n",
    "    \n",
    "    for mun_code, train_res in training_results['train_results'].items():\n",
    "        test_res = training_results['test_results'][mun_code]\n",
    "        \n",
    "        # Calculate normalized metrics\n",
    "        metrics['normalized']['train'][mun_code] = calculate_metrics(\n",
    "            train_res['target_next_4_sum_norm'], train_res['prediction_norm'])\n",
    "        metrics['normalized']['test'][mun_code] = calculate_metrics(\n",
    "            test_res['target_next_4_sum_norm'], test_res['prediction_norm'])\n",
    "        \n",
    "        # Calculate denormalized metrics\n",
    "        metrics['denormalized']['train'][mun_code] = calculate_metrics(\n",
    "            train_res['target_next_4_sum'], train_res['prediction'])\n",
    "        metrics['denormalized']['test'][mun_code] = calculate_metrics(\n",
    "            test_res['target_next_4_sum'], test_res['prediction'])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics\n",
    "try:\n",
    "    evaluation_metrics = create_evaluation_report(training_results)\n",
    "    \n",
    "    # Save metrics\n",
    "    metrics_file = os.path.join(results_dir, 'evaluation_metrics.pkl')\n",
    "    joblib.dump(evaluation_metrics, metrics_file)\n",
    "    print(f\"Evaluation metrics saved to {metrics_file}\")\n",
    "    \n",
    "    # Display aggregate metrics\n",
    "    print(\"\\nAggregate Test Metrics (Normalized):\")\n",
    "    norm_test_metrics = pd.DataFrame(evaluation_metrics['normalized']['test']).T\n",
    "    display(norm_test_metrics.describe())\n",
    "    \n",
    "    print(\"\\nAggregate Test Metrics (Denormalized):\")\n",
    "    denorm_test_metrics = pd.DataFrame(evaluation_metrics['denormalized']['test']).T\n",
    "    display(denorm_test_metrics.describe())\n",
    "except Exception as e:\n",
    "    print(f\"Error calculating metrics: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ef667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating error distribution plot...\n",
      "Creating RMSE comparison plot...\n",
      "Creating RMSE comparison plot...\n",
      "Creating per-municipality visualizations (Top 100 by R2 + São Paulo)...\n",
      "Selected 100 municipalities for detailed plots.\n",
      "Generating plots for 100 municipalities...\n",
      "Processing municipality 3101300...\n",
      "Creating per-municipality visualizations (Top 100 by R2 + São Paulo)...\n",
      "Selected 100 municipalities for detailed plots.\n",
      "Generating plots for 100 municipalities...\n",
      "Processing municipality 3101300...\n",
      "Processing municipality 4305157...\n",
      "Processing municipality 4305157...\n",
      "Processing municipality 3160900...\n",
      "Processing municipality 3160900...\n",
      "Processing municipality 4106555...\n",
      "Processing municipality 4106555...\n",
      "Processing municipality 4323705...\n",
      "Processing municipality 4323705...\n",
      "Processing municipality 2706505...\n",
      "Processing municipality 2706505...\n",
      "Processing municipality 1708254...\n",
      "Processing municipality 1708254...\n",
      "Processing municipality 1702901...\n",
      "Processing municipality 1702901...\n",
      "Processing municipality 3162252...\n",
      "Processing municipality 3162252...\n",
      "Processing municipality 4300646...\n",
      "Processing municipality 4300646...\n",
      "Plotting progress: 10/100 (10%)Processing municipality 5219803...\n",
      "Plotting progress: 10/100 (10%)Processing municipality 5219803...\n",
      "Processing municipality 2922730...\n",
      "Processing municipality 2922730...\n",
      "Processing municipality 2901403...\n",
      "Processing municipality 2901403...\n",
      "Processing municipality 2921054...\n",
      "Processing municipality 2921054...\n",
      "Processing municipality 5206206...\n",
      "Processing municipality 5206206...\n",
      "Processing municipality 2304608...\n",
      "Processing municipality 2304608...\n",
      "Processing municipality 1500107...\n",
      "Processing municipality 1500107...\n",
      "Processing municipality 2202406...\n",
      "Processing municipality 2202406...\n",
      "Processing municipality 2918357...\n",
      "Processing municipality 2918357...\n",
      "Processing municipality 3112059...\n",
      "Processing municipality 3112059...\n",
      "Plotting progress: 20/100 (20%)Processing municipality 1600055...\n",
      "Plotting progress: 20/100 (20%)Processing municipality 1600055...\n",
      "Processing municipality 2210904...\n",
      "Processing municipality 2210904...\n",
      "Processing municipality 4127304...\n",
      "Processing municipality 4127304...\n",
      "Processing municipality 3148509...\n",
      "Processing municipality 3148509...\n",
      "Processing municipality 4312757...\n",
      "Processing municipality 4312757...\n",
      "Processing municipality 4125001...\n",
      "Processing municipality 4125001...\n",
      "Processing municipality 4120705...\n",
      "Processing municipality 4120705...\n",
      "Processing municipality 4204459...\n",
      "Processing municipality 4204459...\n",
      "Processing municipality 4128708...\n",
      "Processing municipality 4128708...\n",
      "Processing municipality 2512721...\n",
      "Processing municipality 2512721...\n",
      "Plotting progress: 30/100 (30%)Processing municipality 2513901...\n",
      "Plotting progress: 30/100 (30%)Processing municipality 2513901...\n",
      "Processing municipality 4106100...\n",
      "Processing municipality 4106100...\n",
      "Processing municipality 2511400...\n",
      "Processing municipality 2511400...\n",
      "Processing municipality 5107941...\n",
      "Processing municipality 5107941...\n",
      "Processing municipality 3147808...\n",
      "Processing municipality 3147808...\n",
      "Processing municipality 2408953...\n",
      "Processing municipality 2408953...\n",
      "Processing municipality 2701506...\n",
      "Processing municipality 2701506...\n",
      "Processing municipality 3518602...\n",
      "Processing municipality 3518602...\n",
      "Processing municipality 3506300...\n",
      "Processing municipality 3506300...\n",
      "Processing municipality 3111002...\n",
      "Processing municipality 3111002...\n",
      "Plotting progress: 40/100 (40%)Processing municipality 1714880...\n",
      "Plotting progress: 40/100 (40%)Processing municipality 1714880...\n",
      "Processing municipality 3521606...\n",
      "Processing municipality 3521606...\n",
      "Processing municipality 2504207...\n",
      "Processing municipality 2504207...\n",
      "Processing municipality 3201209...\n",
      "Processing municipality 3201209...\n",
      "Processing municipality 2803500...\n",
      "Processing municipality 2803500...\n",
      "Processing municipality 2922854...\n",
      "Processing municipality 2922854...\n",
      "Processing municipality 4115309...\n",
      "Processing municipality 4115309...\n",
      "Processing municipality 3164100...\n",
      "Processing municipality 3164100...\n",
      "Processing municipality 2919108...\n",
      "Processing municipality 2919108...\n",
      "Processing municipality 3101201...\n",
      "Processing municipality 3101201...\n",
      "Plotting progress: 50/100 (50%)Processing municipality 3151602...\n",
      "Plotting progress: 50/100 (50%)Processing municipality 3151602...\n",
      "Processing municipality 3549201...\n",
      "Processing municipality 3549201...\n",
      "Processing municipality 3106804...\n",
      "Processing municipality 3106804...\n",
      "Processing municipality 5005152...\n",
      "Processing municipality 5005152...\n",
      "Processing municipality 3554201...\n",
      "Processing municipality 3554201...\n",
      "Processing municipality 2110500...\n",
      "Processing municipality 2110500...\n",
      "Processing municipality 2924702...\n",
      "Processing municipality 2924702...\n",
      "Processing municipality 4308508...\n",
      "Processing municipality 4308508...\n",
      "Processing municipality 3127073...\n",
      "Processing municipality 3127073...\n",
      "Processing municipality 3124906...\n",
      "Processing municipality 3124906...\n",
      "Plotting progress: 60/100 (60%)Processing municipality 2210375...\n",
      "Plotting progress: 60/100 (60%)Processing municipality 2210375...\n",
      "Processing municipality 3528205...\n",
      "Processing municipality 3528205...\n",
      "Processing municipality 3540408...\n",
      "Processing municipality 3540408...\n",
      "Processing municipality 2506103...\n",
      "Processing municipality 2506103...\n",
      "Processing municipality 3529104...\n",
      "Processing municipality 3529104...\n",
      "Processing municipality 3531001...\n",
      "Processing municipality 3531001...\n",
      "Processing municipality 3520608...\n",
      "Processing municipality 3520608...\n",
      "Processing municipality 4109302...\n",
      "Processing municipality 4109302...\n",
      "Processing municipality 5107198...\n",
      "Processing municipality 5107198...\n",
      "Processing municipality 2601003...\n",
      "Processing municipality 2601003...\n",
      "Plotting progress: 70/100 (70%)Processing municipality 2913804...\n",
      "Plotting progress: 70/100 (70%)Processing municipality 2913804...\n",
      "Processing municipality 4302238...\n",
      "Processing municipality 4302238...\n",
      "Processing municipality 2111532...\n",
      "Processing municipality 2111532...\n",
      "Processing municipality 5214051...\n",
      "Processing municipality 5214051...\n",
      "Processing municipality 4209177...\n",
      "Processing municipality 4209177...\n",
      "Processing municipality 2920007...\n",
      "Processing municipality 2920007...\n",
      "Processing municipality 4111803...\n",
      "Processing municipality 4111803...\n",
      "Processing municipality 2911857...\n",
      "Processing municipality 2911857...\n",
      "Processing municipality 2924058...\n",
      "Processing municipality 2924058...\n",
      "Processing municipality 2932507...\n",
      "Processing municipality 2932507...\n",
      "Plotting progress: 80/100 (80%)Processing municipality 4113429...\n",
      "Plotting progress: 80/100 (80%)Processing municipality 4113429...\n",
      "Processing municipality 2920809...\n",
      "Processing municipality 2920809...\n",
      "Processing municipality 5205471...\n",
      "Processing municipality 5205471...\n",
      "Processing municipality 3112307...\n",
      "Processing municipality 3112307...\n",
      "Processing municipality 2614402...\n",
      "Processing municipality 2614402...\n",
      "Processing municipality 3509700...\n",
      "Processing municipality 3509700...\n",
      "Processing municipality 2106201...\n",
      "Processing municipality 2106201...\n",
      "Processing municipality 2104602...\n",
      "Processing municipality 2104602...\n",
      "Processing municipality 3164001...\n",
      "Processing municipality 3164001...\n",
      "Processing municipality 2805505...\n",
      "Processing municipality 2805505...\n",
      "Plotting progress: 90/100 (90%)Processing municipality 4217006...\n",
      "Plotting progress: 90/100 (90%)Processing municipality 4217006...\n",
      "Processing municipality 3551504...\n",
      "Processing municipality 3551504...\n",
      "Processing municipality 2901007...\n",
      "Processing municipality 2901007...\n",
      "Processing municipality 4301859...\n",
      "Processing municipality 4301859...\n",
      "Processing municipality 2506707...\n",
      "Processing municipality 2506707...\n",
      "Processing municipality 3116704...\n",
      "Processing municipality 3116704...\n",
      "Processing municipality 3305000...\n",
      "Processing municipality 3305000...\n",
      "Processing municipality 5205703...\n",
      "Processing municipality 5205703...\n",
      "Processing municipality 2516508...\n",
      "Processing municipality 2516508...\n",
      "Processing municipality 3550308...\n",
      "Processing municipality 3550308...\n",
      "Plotting progress: 100/100 (100%)\n",
      "Finished per-municipality plots.\n",
      "Visualizations saved to results/xgboost_20250505_115446\\visualizations\n",
      "Visualizations created successfully in results/xgboost_20250505_115446\\visualizations\n",
      "Plotting progress: 100/100 (100%)\n",
      "Finished per-municipality plots.\n",
      "Visualizations saved to results/xgboost_20250505_115446\\visualizations\n",
      "Visualizations created successfully in results/xgboost_20250505_115446\\visualizations\n"
     ]
    }
   ],
   "source": [
    "# Function to create visualizations\n",
    "def create_visualizations(training_results, metrics, results_dir):\n",
    "    \"\"\"Create comprehensive visualizations for model evaluation.\"\"\"\n",
    "    # viz_dir is now a subdirectory of the main results_dir for this run\n",
    "    viz_dir = os.path.join(results_dir, 'visualizations')\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        print(\"Creating error distribution plot...\")\n",
    "        # 1. Error Distribution Plot (overall)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        all_errors = []\n",
    "        for mun_code, test_res in training_results['test_results'].items():\n",
    "            errors = test_res['target_next_4_sum'] - test_res['prediction']\n",
    "            all_errors.extend(errors)\n",
    "        \n",
    "        sns.histplot(all_errors, kde=True)\n",
    "        plt.title('Error Distribution Across All Municipalities')\n",
    "        plt.xlabel('Error (Actual - Predicted)')\n",
    "        plt.savefig(os.path.join(viz_dir, 'error_distribution_overall.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"Creating RMSE comparison plot...\")\n",
    "        # 2. Performance Comparison Across Municipalities\n",
    "        try:\n",
    "            metrics_df = pd.DataFrame({\n",
    "                mun: metrics['denormalized']['test'][mun]['RMSE'] \n",
    "                for mun in list(metrics['denormalized']['test'].keys())\n",
    "            }, index=['RMSE']).T\n",
    "            \n",
    "            metrics_df = metrics_df.sort_values('RMSE')\n",
    "            \n",
    "            plt.figure(figsize=(14, 8))\n",
    "            sns.barplot(x=metrics_df.index, y='RMSE', data=metrics_df)\n",
    "            plt.title('RMSE by Municipality')\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(viz_dir, 'rmse_by_municipality.png'))\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating RMSE comparison plot: {e}\")\n",
    "        \n",
    "        # 3. Individual municipality visualizations (sample based on performance)\n",
    "        print(\"Creating per-municipality visualizations (Top 100 by R2 + São Paulo)...\")\n",
    "        \n",
    "        # Get top 100 municipalities by R2 score (denormalized, test set)\n",
    "        try:\n",
    "            denorm_test_metrics = pd.DataFrame(metrics['denormalized']['test']).T.sort_values('R2', ascending=False)\n",
    "            top_munis = denorm_test_metrics.head(100).index.tolist()\n",
    "            \n",
    "            # Ensure São Paulo is included\n",
    "            sao_paulo_code = '3550308'\n",
    "            if sao_paulo_code in training_results['models'] and sao_paulo_code not in top_munis:\n",
    "                if len(top_munis) >= 100:\n",
    "                    top_munis.pop() # Remove the last one to make space if needed\n",
    "                top_munis.append(sao_paulo_code)\n",
    "            \n",
    "            sample_munis = top_munis\n",
    "            print(f\"Selected {len(sample_munis)} municipalities for detailed plots.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error selecting top municipalities, falling back to first 5: {e}\")\n",
    "            sample_munis = list(training_results['models'].keys())[:5]\n",
    "\n",
    "        # Limit to available models just in case\n",
    "        sample_munis = [m for m in sample_munis if m in training_results['models']]\n",
    "        \n",
    "        # Use a simpler progress indicator for plotting\n",
    "        total_plot_munis = len(sample_munis)\n",
    "        print(f\"Generating plots for {total_plot_munis} municipalities...\")\n",
    "        plot_count = 0\n",
    "        update_interval = max(1, total_plot_munis // 10) # Update roughly 10 times\n",
    "\n",
    "        for mun_code in sample_munis:\n",
    "            print(f\"Processing municipality {mun_code}...\")\n",
    "            mun_dir = os.path.join(viz_dir, mun_code)\n",
    "            os.makedirs(mun_dir, exist_ok=True)\n",
    "            \n",
    "            train_res = training_results['train_results'][mun_code]\n",
    "            test_res = training_results['test_results'][mun_code]\n",
    "            model = training_results['models'][mun_code]\n",
    "            \n",
    "            # 3.1 Actual vs Predicted\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.scatter(test_res['target_next_4_sum'], test_res['prediction'], alpha=0.7)\n",
    "            plt.plot([test_res['target_next_4_sum'].min(), test_res['target_next_4_sum'].max()], \n",
    "                    [test_res['target_next_4_sum'].min(), test_res['target_next_4_sum'].max()], \n",
    "                    'r--')\n",
    "            plt.xlabel('Actual')\n",
    "            plt.ylabel('Predicted')\n",
    "            plt.title(f'Actual vs Predicted - Municipality {mun_code}')\n",
    "            plt.savefig(os.path.join(mun_dir, 'actual_vs_predicted.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # 3.2 Time Series Forecast\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            # Use 'date' column for x-axis\n",
    "            plt.plot(test_res['date'], test_res['target_next_4_sum'], 'b-', label='Actual')\n",
    "            plt.plot(test_res['date'], test_res['prediction'], 'r--', label='Predicted')\n",
    "            plt.title(f'Time Series Forecast - Municipality {mun_code}')\n",
    "            plt.xlabel('Date') # Changed label\n",
    "            plt.ylabel('Target (Sum of Next 4 Weeks)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.xticks(rotation=45) # Rotate date labels for better readability\n",
    "            plt.tight_layout() # Adjust layout\n",
    "            plt.savefig(os.path.join(mun_dir, 'time_series_forecast.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # 3.3 Feature Importance\n",
    "            try:\n",
    "                feature_importance = model.feature_importances_\n",
    "                feature_names = training_results['feature_cols']\n",
    "                \n",
    "                importance_df = pd.DataFrame({\n",
    "                    'Feature': feature_names,\n",
    "                    'Importance': feature_importance\n",
    "                }).sort_values('Importance', ascending=False).head(15)\n",
    "                \n",
    "                plt.figure(figsize=(12, 8))\n",
    "                sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
    "                plt.title(f'Feature Importance - Municipality {mun_code}')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(mun_dir, 'feature_importance.png'))\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating feature importance plot for {mun_code}: {e}\")\n",
    "            \n",
    "            # 3.4 Residual Analysis\n",
    "            residuals = test_res['target_next_4_sum'] - test_res['prediction']\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.scatter(test_res['prediction'], residuals)\n",
    "            plt.axhline(y=0, color='r', linestyle='--')\n",
    "            plt.title(f'Residual Analysis - Municipality {mun_code}')\n",
    "            plt.xlabel('Predicted Values')\n",
    "            plt.ylabel('Residuals')\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(mun_dir, 'residual_analysis.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Update progress\n",
    "            plot_count += 1\n",
    "            if plot_count % update_interval == 0 or plot_count == total_plot_munis:\n",
    "                percent_done = int(100 * plot_count / total_plot_munis)\n",
    "                print(f\"\\rPlotting progress: {plot_count}/{total_plot_munis} ({percent_done}%)\", end=\"\")\n",
    "        \n",
    "        print(\"\\nFinished per-municipality plots.\") # Newline after progress\n",
    "\n",
    "        print(f\"Visualizations saved to {viz_dir}\")\n",
    "        return viz_dir\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"Error creating visualizations: {e}\")\n",
    "        print(traceback.format_exc())\n",
    "        return viz_dir\n",
    "\n",
    "# Create visualizations\n",
    "try:\n",
    "    viz_path = create_visualizations(training_results, evaluation_metrics, results_dir)\n",
    "    print(f\"Visualizations created successfully in {viz_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating visualizations: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f0e7e",
   "metadata": {},
   "source": [
    "## 8. Results Summary\n",
    "\n",
    "Let's summarize the results and create a final report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d21e276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== XGBoost Training Summary ===\n",
      "Timestamp: 20250505_115446\n",
      "Total municipalities: 5028\n",
      "Models successfully trained: 5028\n",
      "Models failed: 0\n",
      "Municipalities skipped: 0\n",
      "\n",
      "Average Test Metrics (Denormalized):\n",
      "  MAE: 0.7859\n",
      "  RMSE: 0.9380\n",
      "  R2: -7.8900\n",
      "\n",
      "Best municipalities by R²:\n",
      "  1. 3101300: R² = 0.9848\n",
      "  2. 4305157: R² = 0.9318\n",
      "  3. 3160900: R² = 0.9131\n",
      "  4. 4106555: R² = 0.9069\n",
      "  5. 4323705: R² = 0.8954\n",
      "\n",
      "Results saved to:\n",
      "  Models: models/xgboost_20250505_115446\n",
      "  Results: results/xgboost_20250505_115446\n"
     ]
    }
   ],
   "source": [
    "# Create a summary report\n",
    "def create_summary_report(training_results, metrics, results_dir):\n",
    "    \"\"\"Create a comprehensive summary report of the modeling results.\"\"\"\n",
    "    # Count successful models\n",
    "    successful_models = len(training_results['models'])\n",
    "    failed_models = len(training_results['errors'])\n",
    "    total_municipalities = successful_models + failed_models + len(skipped_munis)\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    norm_test_metrics = pd.DataFrame(metrics['normalized']['test']).T\n",
    "    denorm_test_metrics = pd.DataFrame(metrics['denormalized']['test']).T\n",
    "    \n",
    "    # Create report dictionary\n",
    "    report = {\n",
    "        'timestamp': timestamp,\n",
    "        'model_counts': {\n",
    "            'successful': successful_models,\n",
    "            'failed': failed_models,\n",
    "            'skipped': len(skipped_munis),\n",
    "            'total': total_municipalities\n",
    "        },\n",
    "        'average_metrics': {\n",
    "            'normalized': norm_test_metrics.mean().to_dict(),\n",
    "            'denormalized': denorm_test_metrics.mean().to_dict()\n",
    "        },\n",
    "        'best_municipalities': {\n",
    "            'by_rmse': denorm_test_metrics.sort_values('RMSE').iloc[:5].index.tolist(),\n",
    "            'by_r2': denorm_test_metrics.sort_values('R2', ascending=False).iloc[:5].index.tolist()\n",
    "        },\n",
    "        'worst_municipalities': {\n",
    "            'by_rmse': denorm_test_metrics.sort_values('RMSE', ascending=False).iloc[:5].index.tolist(),\n",
    "            'by_r2': denorm_test_metrics.sort_values('R2').iloc[:5].index.tolist()\n",
    "        },\n",
    "        'paths': {\n",
    "            'models': models_dir,\n",
    "            'results': results_dir\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save report to JSON\n",
    "    report_file = os.path.join(results_dir, 'summary_report.json')\n",
    "    with open(report_file, 'w') as f:\n",
    "        import json\n",
    "        json.dump(report, f, indent=2)\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Create and display summary report\n",
    "try:\n",
    "    summary = create_summary_report(training_results, evaluation_metrics, results_dir)\n",
    "    print(\"\\n=== XGBoost Training Summary ===\")\n",
    "    print(f\"Timestamp: {summary['timestamp']}\")\n",
    "    print(f\"Total municipalities: {summary['model_counts']['total']}\")\n",
    "    print(f\"Models successfully trained: {summary['model_counts']['successful']}\")\n",
    "    print(f\"Models failed: {summary['model_counts']['failed']}\")\n",
    "    print(f\"Municipalities skipped: {summary['model_counts']['skipped']}\")\n",
    "    print(\"\\nAverage Test Metrics (Denormalized):\")\n",
    "    for metric, value in summary['average_metrics']['denormalized'].items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    print(\"\\nBest municipalities by R²:\")\n",
    "    for i, mun in enumerate(summary['best_municipalities']['by_r2']):\n",
    "        r2 = evaluation_metrics['denormalized']['test'][mun]['R2']\n",
    "        print(f\"  {i+1}. {mun}: R² = {r2:.4f}\")\n",
    "    print(\"\\nResults saved to:\")\n",
    "    print(f\"  Models: {summary['paths']['models']}\")\n",
    "    print(f\"  Results: {summary['paths']['results']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating summary report: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd83136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
